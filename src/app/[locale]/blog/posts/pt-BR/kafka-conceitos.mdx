---
title: "Kafka: Aprenda de uma vez por todas como funciona e como executar localmente"
publishedAt: "2025-02-01"
image: "/images/posts/kafka-conceitos/kafka-logo.jpg"
summary: "Conhecer o conceito de idempotência é fundamental para qualquer desenvolvedor, vamos explorar isso juntos?"
tag: "tecnologia"
---

![Cover foto.](/images/posts/kafka-conceitos/kafka-logo.jpg)

# Introdução

Um dos pontos mais importantes quando vamos arquitetar sistemas distribuídos é sem dúvida definir como será feita a comunicação entre os componentes. 

Quando o assunto é comunicação entre processos, precisamos pensar em aspectos como: 

- A comunicação pode ser feita de forma **assíncrona**?
- É necessário um **alto throughput**?
- A mesma mensagem precisa ou pode ser **comunicada para componentes diferentes**?
- Precisamos de **tolerância a falhas** durante o processamento da mensagem?

Se a resposta para essas perguntas é sim, provavelmente a melhor opção à disposição é usar uma aplicação como o <a href={"https://kafka.apache.org/"}  target={"_blank"} rel={"noopener noreferrer"}>Apache Kafka</a> para intermediar a produção e consumo das mensagens entre os componentes do sistema. 

O Kafka é uma **plataforma de streaming de eventos** que permite com que aplicações:

1. **Publiquem** (escrevam) e **se inscrevam** (leiam) em streams de eventos.
2. **Armazenem** streams de eventos de forma **durável** e **confiável**
3. **Processem** streams de eventos **assim que eles acontecem** ou **de forma retrospectiva**

O aspecto mais importante do Kafka é que ele faz isso de uma forma **escalável**, **distribuída**, **tolerante a falhas** e **segura**.

Eu sei que à primeira vista todos esses termos podem ser confusos e que pode ser difícil estabelecer uma imagem clara de como todas essas peças se "encaixam". É importante reconhecer que o Kafka realmente é um componente complexo e entender como ele funciona com todos os detalhes necessários é uma tarefa difícil. 

Nesse artigo eu vou dar o meu melhor para explicar da forma mais simples e completa possível seu funcionamento e no fim vamos conseguir criar e interagir com esse serviço localmente, dando nosso primeiro passo nessa jornada. Bora lá?

# Eventos

Anteriormente definimos o kafka como uma plataforma de streaming de eventos, mas o que exatamente são esses eventos? Um evento é um registro de algum acontecimento, a representação de um fato, também podem ser chamados de **mensagens** ou **registros** na documentação do kafka

Quando interagimos com o Kafka fazemos isso lendo ou escrevendo eventos para ele. Uma propriedade importante de um evento é que ele pode ser visto como um registro em um **log**, ou seja, ele é persistente e imutável.

Eventos no kafka tem três campos principais: uma **chave**, um **valor** e um **timestamp**. Além desses campos temos ainda headers opcionais para adicionar metadados. O dado a seguir é um exemplo de evento:

<CodeBlock className="my-24"
    compact
    codeInstances={[
        {
            code: `{
    "key": "Daniel",
    "value": "Entrou em sua conta",
    "timestamp": "2025 8:52:32 AM GMT-03:00"
}`,
            label: 'example event',
            language: 'json'
        },
    ]}
    copyButton
/>

# Brokers

O Apache Kafka foi desenvolvido para atuar como um **cluster**, isso é, coordenando diversos **nós** executando a aplicação para garantir tolerância a falhas e escalabilidade. Dessa forma é possível escalar o cluster horizontalmente adicionando novos nós caso seja necessário um aumento na performance, ou então adicionar mais garantias de redundância, ja que se um dos nós falharem ele é capaz de acionar outro nó para atuar em seu lugar.

Na forma mais tradicional de operar um cluster de Apache Kafka é necessário instanciar uma aplicação extra separadamente chamada <a href={"https://zookeeper.apache.org/"} target={"_blank"} rel={"noopener noreferrer"}>Apache ZooKeeper</a>. Esse componente fica responsável principalmente por realizar um conscenso entre os nós do cluster sobre quem serão os líderes de cada partição e gerenciar os metadados do cluster.

No entando a partir da versão <a href={"https://www.confluent.io/blog/apache-kafka-3-3-0-new-features-and-updates/"} target={"_blank"} rel={"noopener noreferrer"}>3.3</a> o Kafka da a possibilidade de utilizar o <a href={"https://developer.confluent.io/learn/kraft/"} target={"_blank"} rel={"noopener noreferrer"}>KRaft</a> como protocolo de consenso. Essa opção elimina a necessidade de instanciar uma aplicação como o ZooKeeper separadamente pois a lógica já está inclusa no próprio Kafka, simplificando o processo de criar um cluster!

Ao utilizar o KRaft, um nó de um cluster Kafka pode atuar em dois papeis distintos: como **broker** e/ou como um **controller**. Um broker é uma instância rodando Kafka que atua gerenciando eventos, já um controller atua armazenando metadados do cluster e realizando papeis de consenso entre os nós.

# Tópicos e Partições

Quando escrevemos e consumimos eventos do Kafka fazemos isso publicando e consumindo de **tópicos**. Essa abstração é como se fosse um  

![Topics .](/images/posts/kafka-conceitos/topicos.jpg)